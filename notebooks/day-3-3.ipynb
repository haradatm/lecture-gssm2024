{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f6ed6-79e9-4efc-836a-040000ce8c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# day 3-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b43ff",
   "metadata": {},
   "source": [
    "このノートブックの実行例は[こちら(HTML版)](../notebooks-sample/day-4.html)で確認できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7303c7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9bc8c-8096-4d76-b983-250b7a4b8203",
   "metadata": {},
   "source": [
    "## 0. はじめに"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a794a09-51b9-449b-b699-32a6318de81b",
   "metadata": {},
   "source": [
    "ページ上部のメニューバーにある **Kernel** メニューをクリックし、プルダウンメニューから [**Change Kernel ...**] を選び、**gssm2023:Python** を選択してください。\n",
    "\n",
    "<img src=\"images/change_kernel1.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097064cc-d520-4893-a0e6-16ff5b34c15a",
   "metadata": {},
   "source": [
    "ノートブック上部の右隅に表示されたカーネル名が **gssm2023:Python** になっていることを確認してください。\n",
    "\n",
    "<img src=\"images/change_kernel2.png\" width=\"30%\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bd5b1-64b2-4113-90c7-f31684ed2860",
   "metadata": {},
   "source": [
    "## 1. KHCoder のテキスト解析&分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0ca9d",
   "metadata": {},
   "source": [
    "### 1.0 事前準備 (定義済み関数の読み込み)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ee7c5-a814-455c-93ca-b4989fbd6f68",
   "metadata": {},
   "source": [
    "以下のセルを**修正せず**に実行してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gssm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa2dec-da82-4b61-a10d-d00aad109f41",
   "metadata": {},
   "source": [
    "### 1.1 データのダウンロード (前回ダウンロード済みのためスキップ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1c51f-947e-49aa-a71f-9ab3185e06fa",
   "metadata": {},
   "source": [
    "以下のデータがダウンロード済みです"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c44667-eeb0-4acd-b5ea-5039e225129f",
   "metadata": {
    "tags": []
   },
   "source": [
    "| ファイル名 | 件数 | データセット | 備考 |\n",
    "| --- | --- | --- | --- |\n",
    "| rakuten-1000-2023-2024.xlsx.zip | 10,000 | •レジャー+ビジネスの 10エリア<br>•エリアごと 1,000件 (ランダムサンプリング)<br>•期間: 2023/1~2024 GW明け | 本講義の全体を通して使用する |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d4536-de4f-4cd7-b6ce-e1ed5e60bd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# もし、再度ダウンロードが必要な場合は残りの行のコメントマーク「#」を除去して、このセルを再実行してください\n",
    "\n",
    "# FILE_ID = \"1EeCuDrfKdlsMxG9p3Ot7TIxfV9_f2smY\"\n",
    "# !gdown --id {FILE_ID}\n",
    "# !unzip rakuten-1000-2023-2024.xlsx.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9daa65-996b-4c16-bfc6-5e8de843291c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 データの読み込み (DataFrame型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd612f-4a36-40ef-9685-c4898fafd177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_excel(\"rakuten-1000-2023-2024.xlsx\")\n",
    "print(all_df.shape)\n",
    "display(all_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc5bee-fefd-4fe5-98e2-eee3d7965ab3",
   "metadata": {},
   "source": [
    "### 1.3 「文書-抽出語」表 を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217a28a-284e-41a1-b981-ff59d3ed3a36",
   "metadata": {},
   "source": [
    "コメント列から単語を抽出する (単語を品詞「名詞」「形容詞」「未知語」で絞り込む)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849575f-a94e-4805-b411-cdfc7d76dcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from collections import defaultdict\n",
    "import MeCab\n",
    "\n",
    "# mecab の初期化\n",
    "tagger = MeCab.Tagger(\"-r ../tools/usr/local/etc/mecabrc --unk-feature 未知語\")\n",
    "\n",
    "# 単語頻度辞書の初期化\n",
    "word_counts = defaultdict(lambda: 0)\n",
    "\n",
    "# 抽出語情報リストの初期化\n",
    "words = []\n",
    "\n",
    "# 半角->全角変換マクロを定義する\n",
    "ZEN = \"\".join(chr(0xff01 + i) for i in range(94))\n",
    "HAN = \"\".join(chr(0x21 + i) for i in range(94))\n",
    "HAN2ZEN = str.maketrans(HAN, ZEN)\n",
    "\n",
    "# ストップワードを定義する\n",
    "# stopwords = ['する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう']\n",
    "stopwords = [\"湯畑\"]\n",
    "\n",
    "# データ1行ごとのループ\n",
    "for index, row in all_df.iterrows():\n",
    "\n",
    "    # 半角->全角変換した後で, mecab で解析する\n",
    "    node = tagger.parseToNode(row[\"コメント\"].translate(HAN2ZEN))\n",
    "\n",
    "    # 形態素ごとのループ\n",
    "    while node:\n",
    "        # 解析結果を要素ごとにバラす\n",
    "        features = node.feature.split(',')\n",
    "\n",
    "        # 品詞1 を取り出す\n",
    "        pos1 = features[0]\n",
    "\n",
    "        # 品詞2 を取り出す\n",
    "        pos2 = features[1] if len(features) > 1 else \"\"\n",
    "\n",
    "        # 原形 を取り出す\n",
    "        base = features[6] if len(features) > 6 else None\n",
    "\n",
    "        # 原型がストップワードに含まれない単語のみ抽出する\n",
    "        if base not in stopwords:\n",
    "\n",
    "            # 「名詞-一般」\n",
    "            if (pos1 == \"名詞\" and pos2 == \"一般\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"名詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容動詞」\n",
    "            elif (pos1 == \"名詞\" and pos2 == \"形容動詞語幹\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                base = f\"{base}だ\"\n",
    "                postag = \"形容動詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容詞」\n",
    "            elif pos1 == \"形容詞\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"形容詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「未知語」\n",
    "            elif pos1 == \"未知語\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"未知語\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "        # 次の形態素へ\n",
    "        node = node.next\n",
    "\n",
    "# DataFrme 型に整える\n",
    "columns = [\n",
    "    \"文書ID\",\n",
    "    # \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"品詞\",\n",
    "    \"カテゴリー\",\n",
    "    \"エリア\",\n",
    "    \"dict_key\",\n",
    "]\n",
    "docs_df = pd.DataFrame(words, columns=columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(docs_df.shape)\n",
    "display(docs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a03c6f-1a67-4e96-a78f-ec471d4098d5",
   "metadata": {},
   "source": [
    "抽出語の出現頻度をカウントする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bed21-5e42-4f00-8bc9-32ed5b0a5a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表から単語の出現回数をカウントする\n",
    "word_list = []\n",
    "for i, (k, v) in enumerate(sorted(word_counts.items(), key=lambda x:x[1], reverse=True)):\n",
    "    word_list.append((i, k[0], v, k))\n",
    "\n",
    "# DataFrame 型に整える\n",
    "columns = [\n",
    "    \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"出現頻度\",\n",
    "    \"dict_key\"\n",
    "]\n",
    "\n",
    "# DataFrame を表示する\n",
    "word_counts_df = pd.DataFrame(word_list, columns=columns)\n",
    "print(word_counts_df.shape)\n",
    "display(word_counts_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7146cc",
   "metadata": {},
   "source": [
    "単語IDを紐つける (出現回数 Top 150語のみ抽出する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127684b-da31-4a70-ab00-8900f3ffed27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 150語のみ抽出する\n",
    "word_counts_150_df = word_counts_df[0:150]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 150語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_150_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_150_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# DataFrame を表示する\n",
    "# print(docs_150_df.shape)\n",
    "display(docs_150_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f9543",
   "metadata": {},
   "source": [
    "「文書-抽出語」表 を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9780cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 75語のみ抽出する\n",
    "word_counts_75_df = word_counts_df[0:75]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 75語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_75_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_75_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# 「カテゴリー,エリア」でクロス集計する\n",
    "cross_75_df = pd.crosstab(\n",
    "    [\n",
    "        docs_75_df['カテゴリー'], \n",
    "        docs_75_df['エリア'], \n",
    "        docs_75_df['文書ID']\n",
    "    ], \n",
    "    docs_75_df['単語ID'], margins=False\n",
    ")\n",
    "cross_75_df.columns = word_counts_75_df[\"表層\"]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a21bd7",
   "metadata": {},
   "source": [
    "「文書-抽出語」 表を {0,1} に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f09b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表を {0,1} に変換する\n",
    "cross_75_df[cross_75_df > 0] = 1\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c38df",
   "metadata": {},
   "source": [
    "### 1.4 共起ネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9fcf4",
   "metadata": {},
   "source": [
    "共起度行列を作成する (抽出語-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ebe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "# 共起行列を作成する\n",
    "X = cross_75_df.values\n",
    "X = csc_matrix(X)\n",
    "Xc = (X.T * X)\n",
    "# 対角成分のみにする\n",
    "Xc = np.triu(Xc.toarray())\n",
    "\n",
    "# DataFrame 型に整える\n",
    "cooccur_75_df = pd.DataFrame(Xc, columns=cross_75_df.columns, index=cross_75_df.columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cooccur_75_df.shape)\n",
    "display(cooccur_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e70e5",
   "metadata": {},
   "source": [
    "#### (a) 共起ネットワーク (共起度の高いエッジを残す)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa653d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出語の出現回数(ノードの大きさ)を取得する\n",
    "word_counts = cross_75_df.sum(axis=0).values\n",
    "\n",
    "# 共起行列(共起度)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_cooccur_network(cooccur_75_df, word_counts, cooccur_75_df.values.max() * 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c11eab",
   "metadata": {},
   "source": [
    "#### (b) 共起ネットワーク (Jaccard 係数が上位のエッジを残す)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266589c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共起行列の中身を Jaccard 係数に入れ替える\n",
    "jaccard_75_df = gssm_utils.jaccard_coef(cooccur_75_df, cross_75_df)\n",
    "\n",
    "# 抽出語の出現回数(ノードの大きさ)を取得する\n",
    "word_counts = cross_75_df.sum(axis=0).values\n",
    "\n",
    "# 共起行列(Jaccard係数)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_cooccur_network(jaccard_75_df, word_counts, np.sort(jaccard_75_df.values.reshape(-1))[::-1][60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e8170",
   "metadata": {},
   "source": [
    "### 1.5 対応分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cbebf-a89c-4685-9d79-db4ffe6ad50d",
   "metadata": {},
   "source": [
    "「文書-抽出語」 表を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c8727",
   "metadata": {},
   "source": [
    "「外部変数-抽出語」 クロス集計表を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb120f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_75_df = pd.concat(\n",
    "    [\n",
    "        cross_75_df.groupby(level='カテゴリー').sum(), \n",
    "        cross_75_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_75_df.shape)\n",
    "display(aggregate_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72377b8a",
   "metadata": {},
   "source": [
    "#### (a) 対応分析プロット (ライブラリ mca を使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fb35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "import mca\n",
    "\n",
    "# ライブラリ mca による対応分析\n",
    "ncols = aggregate_75_df.shape[1]\n",
    "mca_ben = mca.MCA(aggregate_75_df, ncols=ncols, benzecri=False)\n",
    "\n",
    "# 行方向および列方向の値を取り出す\n",
    "row_coord = mca_ben.fs_r(N=2)\n",
    "col_coord = mca_ben.fs_c(N=2)\n",
    "\n",
    "# 固有値を求める\n",
    "eigenvalues = mca_ben.L\n",
    "total = np.sum(eigenvalues)\n",
    "# 寄与率を求める\n",
    "explained_inertia = 100 * eigenvalues / total\n",
    "\n",
    "# 行方向および列方向のラベルを取得する\n",
    "row_labels = aggregate_75_df.index\n",
    "col_labels = aggregate_75_df.columns\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_coresp(row_coord, col_coord,row_labels, col_labels, explained_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326f895",
   "metadata": {},
   "source": [
    "#### (b) 対応分析プロット (カイ2乗値を手計算してプロットする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_N = aggregate_75_df.values\n",
    "row_sum = table_N.sum(axis=1)\n",
    "col_sum = table_N.sum(axis=0)\n",
    "n = aggregate_75_df.values.sum()\n",
    "\n",
    "# カイ2乗値を求める\n",
    "expected = np.outer(row_sum, col_sum) / n\n",
    "chisq = np.square(table_N - expected) / expected\n",
    "residuals = (table_N - expected) / np.sqrt(expected)\n",
    "\n",
    "# Standardized residuals\n",
    "residuals = residuals / np.sqrt(n)\n",
    "\n",
    "# Number of dimensions\n",
    "nb_axes = min(residuals.shape[0]-1, residuals.shape[1]-1)\n",
    "\n",
    "# Singular value decomposition\n",
    "U, s, V = np.linalg.svd(residuals, full_matrices=True)\n",
    "sv = s[:nb_axes]\n",
    "u = U[:, :nb_axes]\n",
    "v = V[:nb_axes, :]\n",
    "\n",
    "# row mass\n",
    "row_mass = row_sum / n\n",
    "\n",
    "# row coord = u * sv /sqrt(row.mass)\n",
    "row_coord = (u * sv) / np.sqrt(row_mass)[:, np.newaxis]\n",
    "\n",
    "# col mass\n",
    "col_mass = col_sum / n\n",
    "\n",
    "# row coord = sv * vT /sqrt(col.mass)\n",
    "col_coord = (sv * v.T) / np.sqrt(col_mass)[:, np.newaxis]\n",
    "\n",
    "# 固有値を求める\n",
    "eige_nvalue = s ** 2\n",
    "\n",
    "# 寄与率を求める\n",
    "explained_inertia = 100 * eige_nvalue / sum(eige_nvalue)\n",
    "\n",
    "# 行方向および列方向のラベルを取得する\n",
    "row_labels = aggregate_75_df.index\n",
    "col_labels = aggregate_75_df.columns\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_coresp(row_coord, col_coord,row_labels, col_labels, explained_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e510d6f",
   "metadata": {},
   "source": [
    "#### (c) 対応分析プロット (共起頻度のままプロットする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b936d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "table_N = aggregate_75_df.values\n",
    "table_P = table_N / aggregate_75_df.values.max()\n",
    "\n",
    "# Singular value decomposition\n",
    "U, s, V = np.linalg.svd(table_P, full_matrices=True)\n",
    "sv = s[:nb_axes]\n",
    "u = U[:, :nb_axes]\n",
    "v = V[:nb_axes, :]\n",
    "\n",
    "# row mass\n",
    "row_mass = row_sum / n\n",
    "\n",
    "# row coord = u * sv /sqrt(row.mass)\n",
    "row_coord = (u * sv) / np.sqrt(row_mass)[:, np.newaxis]\n",
    "\n",
    "# col mass\n",
    "col_mass = col_sum / n\n",
    "\n",
    "# row coord = sv * vT /sqrt(col.mass)\n",
    "col_coord = (sv * v.T) / np.sqrt(col_mass)[:, np.newaxis]\n",
    "\n",
    "# 固有値を求める\n",
    "eige_nvalue = s ** 2\n",
    "\n",
    "# 寄与率を求める \n",
    "explained_inertia = 100 * eige_nvalue / sum(eige_nvalue)\n",
    "\n",
    "# 行方向および列方向のラベルを取得する\n",
    "row_labels = aggregate_75_df.index\n",
    "col_labels = aggregate_75_df.columns\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_coresp(row_coord, col_coord,row_labels, col_labels, explained_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c3997",
   "metadata": {},
   "source": [
    "#### (d) PCAプロット (共起頻度のままプロットする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "table_N = aggregate_75_df.values\n",
    "\n",
    "# ライブラリ PCA による主成分分析\n",
    "pca = PCA()\n",
    "\n",
    "reduced = pca.fit_transform(table_N.T)\n",
    "coeff = np.transpose(pca.components_)\n",
    "var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "scalex = 1.0 / (reduced[:,0].max() - reduced[:,0].min())\n",
    "scaley = 1.0 / (reduced[:,1].max() - reduced[:,1].min())\n",
    "reduced[:,0] *= scalex\n",
    "reduced[:,1] *= scaley\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_pca(coeff, reduced, row_labels, col_labels, var_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d3e6d",
   "metadata": {},
   "source": [
    "#### (e) PCAプロット (カイ2乗値をプロットする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "table_N = aggregate_75_df.values\n",
    "row_sum = table_N.sum(axis=1)\n",
    "col_sum = table_N.sum(axis=0)\n",
    "n = aggregate_75_df.values.sum()\n",
    "\n",
    "# カイ2乗値を求める\n",
    "expected = np.outer(row_sum, col_sum) / n\n",
    "chisq = np.square(table_N - expected) / expected\n",
    "residuals = (table_N - expected) / np.sqrt(expected)\n",
    "\n",
    "# Standardized residuals\n",
    "residuals = residuals / np.sqrt(n)\n",
    "\n",
    "# ライブラリ PCA による主成分分析\n",
    "pca = PCA()\n",
    "\n",
    "reduced = pca.fit_transform(residuals.T)\n",
    "coeff = np.transpose(pca.components_)\n",
    "var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "scalex = 1.0 / (reduced[:,0].max() - reduced[:,0].min())\n",
    "scaley = 1.0 / (reduced[:,1].max() - reduced[:,1].min())\n",
    "reduced[:,0] *= scalex\n",
    "reduced[:,1] *= scaley\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_pca(coeff, reduced, row_labels, col_labels, var_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75393415-d02b-4c1c-bd74-7ed033bf3c47",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gssm2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
