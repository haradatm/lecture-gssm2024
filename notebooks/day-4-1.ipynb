{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f6ed6-79e9-4efc-836a-040000ce8c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# day 4-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ad82b-56cd-469e-9d1a-1c3f76c25385",
   "metadata": {},
   "source": [
    "このノートブックの実行例は[こちら(HTML版)](../notebooks-sample/day-4-1.html)で確認できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b026be-871b-4e1b-b6f2-86af31885045",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9bc8c-8096-4d76-b983-250b7a4b8203",
   "metadata": {},
   "source": [
    "## 0. はじめに"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a794a09-51b9-449b-b699-32a6318de81b",
   "metadata": {},
   "source": [
    "ページ上部のメニューバーにある **Kernel** メニューをクリックし、プルダウンメニューから [**Change Kernel ...**] を選び、**gssm2024:Python** を選択してください。\n",
    "\n",
    "<img src=\"images/change_kernel1.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097064cc-d520-4893-a0e6-16ff5b34c15a",
   "metadata": {},
   "source": [
    "ノートブック上部の右隅に表示されたカーネル名が **gssm2024:Python** になっていることを確認してください。\n",
    "\n",
    "<img src=\"images/change_kernel2.png\" width=\"30%\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bd5b1-64b2-4113-90c7-f31684ed2860",
   "metadata": {},
   "source": [
    "## 1. テキスト分析 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63ae02-8b65-425f-958a-628f771494a8",
   "metadata": {},
   "source": [
    "### 1.0 事前準備 (定義済み関数の読み込み)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce76ea-4a7a-44a6-a6a9-7556f9c1dc7c",
   "metadata": {},
   "source": [
    "以下のセルを**修正せず**に実行してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dcc07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gssm_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa2dec-da82-4b61-a10d-d00aad109f41",
   "metadata": {},
   "source": [
    "### 1.1 データのダウンロード (前回ダウンロード済みのためスキップ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1c51f-947e-49aa-a71f-9ab3185e06fa",
   "metadata": {},
   "source": [
    "以下のデータがダウンロード済みです"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c44667-eeb0-4acd-b5ea-5039e225129f",
   "metadata": {
    "tags": []
   },
   "source": [
    "| ファイル名 | 件数 | データセット | 備考 |\n",
    "| --- | --- | --- | --- |\n",
    "| rakuten-1000-2023-2024.xlsx.zip | 10,000 | •レジャー+ビジネスの 10エリア<br>•エリアごと 1,000件 (ランダムサンプリング)<br>•期間: 2023/1~2024 GW明け | 本講義の全体を通して使用する |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d4536-de4f-4cd7-b6ce-e1ed5e60bd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# もし、再度ダウンロードが必要な場合は残りの行のコメントマーク「#」を除去して、このセルを再実行してください\n",
    "\n",
    "# FILE_ID = \"1EeCuDrfKdlsMxG9p3Ot7TIxfV9_f2smY\"\n",
    "# !gdown --id {FILE_ID}\n",
    "# !unzip -o rakuten-1000-2023-2024.xlsx.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9daa65-996b-4c16-bfc6-5e8de843291c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 データの読み込み (DataFrame型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd612f-4a36-40ef-9685-c4898fafd177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_excel(\"rakuten-1000-2023-2024.xlsx\")\n",
    "print(all_df.shape)\n",
    "display(all_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc5bee-fefd-4fe5-98e2-eee3d7965ab3",
   "metadata": {},
   "source": [
    "### 1.3 単語の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217a28a-284e-41a1-b981-ff59d3ed3a36",
   "metadata": {},
   "source": [
    "コメント列から単語を抽出する (単語を品詞「名詞」「形容詞」「未知語」で絞り込む)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849575f-a94e-4805-b411-cdfc7d76dcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from collections import defaultdict\n",
    "import MeCab\n",
    "\n",
    "# mecab の初期化\n",
    "tagger = MeCab.Tagger(\"-r ../tools/usr/local/etc/mecabrc --unk-feature 未知語\")\n",
    "\n",
    "# 単語頻度辞書の初期化\n",
    "word_counts = defaultdict(lambda: 0)\n",
    "\n",
    "# 抽出語情報リストの初期化\n",
    "words = []\n",
    "\n",
    "# 半角->全角変換マクロを定義する\n",
    "ZEN = \"\".join(chr(0xff01 + i) for i in range(94))\n",
    "HAN = \"\".join(chr(0x21 + i) for i in range(94))\n",
    "HAN2ZEN = str.maketrans(HAN, ZEN)\n",
    "\n",
    "# ストップワードを定義する\n",
    "# stopwords = ['する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう']\n",
    "stopwords = [\"湯畑\"]\n",
    "\n",
    "# データ1行ごとのループ\n",
    "for index, row in all_df.iterrows():\n",
    "\n",
    "    # 半角->全角変換した後で, mecab で解析する\n",
    "    node = tagger.parseToNode(row[\"コメント\"].translate(HAN2ZEN))\n",
    "\n",
    "    # 形態素ごとのループ\n",
    "    while node:\n",
    "        # 解析結果を要素ごとにバラす\n",
    "        features = node.feature.split(',')\n",
    "\n",
    "        # 品詞1 を取り出す\n",
    "        pos1 = features[0]\n",
    "\n",
    "        # 品詞2 を取り出す\n",
    "        pos2 = features[1] if len(features) > 1 else \"\"\n",
    "\n",
    "        # 原形 を取り出す\n",
    "        base = features[6] if len(features) > 6 else None\n",
    "\n",
    "        # 原型がストップワードに含まれない単語のみ抽出する\n",
    "        if base not in stopwords:\n",
    "\n",
    "            # 「名詞-一般」\n",
    "            if (pos1 == \"名詞\" and pos2 == \"一般\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"名詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容動詞」\n",
    "            elif (pos1 == \"名詞\" and pos2 == \"形容動詞語幹\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                base = f\"{base}だ\"\n",
    "                postag = \"形容動詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容詞」\n",
    "            elif pos1 == \"形容詞\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"形容詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「未知語」\n",
    "            elif pos1 == \"未知語\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"未知語\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "        # 次の形態素へ\n",
    "        node = node.next\n",
    "\n",
    "# DataFrme 型に整える\n",
    "columns = [\n",
    "    \"文書ID\",\n",
    "    # \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"品詞\",\n",
    "    \"カテゴリー\",\n",
    "    \"エリア\",\n",
    "    \"dict_key\",\n",
    "]\n",
    "docs_df = pd.DataFrame(words, columns=columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(docs_df.shape)\n",
    "display(docs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a591f4-512a-41c4-ae83-b9014096dd09",
   "metadata": {},
   "source": [
    "### 1.4 単語の出現回数 (Top 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a03c6f-1a67-4e96-a78f-ec471d4098d5",
   "metadata": {},
   "source": [
    "単語の出現回数をカウントする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bed21-5e42-4f00-8bc9-32ed5b0a5a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表から単語の出現回数をカウントする\n",
    "word_list = []\n",
    "for i, (k, v) in enumerate(sorted(word_counts.items(), key=lambda x:x[1], reverse=True)):\n",
    "    word_list.append((i, k[0], v, k))\n",
    "\n",
    "# DataFrame 型に整える\n",
    "columns = [\n",
    "    \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"出現頻度\",\n",
    "    \"dict_key\"\n",
    "]\n",
    "word_counts_df = pd.DataFrame(word_list, columns=columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(word_counts_df.shape)\n",
    "display(word_counts_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe27d68",
   "metadata": {},
   "source": [
    "単語IDを紐つける (出現回数 Top 150語のみ抽出する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127684b-da31-4a70-ab00-8900f3ffed27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 150語のみ抽出する\n",
    "word_counts_150_df = word_counts_df[0:150]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 150語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_150_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_150_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(docs_150_df.shape)\n",
    "display(docs_150_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec122799-b82c-4916-aff6-40db98deb874",
   "metadata": {},
   "source": [
    "### 1.5 ワードクラウド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538108f3-34fb-4b05-a120-60623c54bfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 出現回数Top 75単語でワードクラウドを作成する\n",
    "words = ' '.join(word_counts_df['表層'][0:75])\n",
    "gssm_utils.plot_wordcloud(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc2c3c-3383-4e49-b678-471d3f7a530a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.6 「文書-抽出語」表の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f00bf0",
   "metadata": {},
   "source": [
    "「文書-抽出語」表を作成する (出現回数 Top 75語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadd536-1426-4c17-ab7e-2b7156116d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 75語のみ抽出する\n",
    "word_counts_75_df = word_counts_df[0:75]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 75語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_75_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_75_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# 「カテゴリー,エリア」でクロス集計する\n",
    "cross_75_df = pd.crosstab(\n",
    "    [\n",
    "        docs_75_df['カテゴリー'], \n",
    "        docs_75_df['エリア'], \n",
    "        docs_75_df['文書ID']\n",
    "    ], \n",
    "    docs_75_df['単語ID'], margins=False\n",
    ")\n",
    "cross_75_df.columns = word_counts_75_df[\"表層\"]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651952b",
   "metadata": {},
   "source": [
    "「文書-抽出語」 表を {0,1} に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表を {0,1} に変換する\n",
    "cross_75_df[cross_75_df > 0] = 1\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11786769-22aa-44e3-a817-2a593497f00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.7 共起ネットワーク図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48c9db-bbed-43a8-8451-4709abebd87a",
   "metadata": {},
   "source": [
    "#### 1.7.1 共起度行列を作成する (抽出語-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c37515-b171-446a-9020-8f6e1391facf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "# 共起行列を作成する\n",
    "X = cross_75_df.values\n",
    "X = csc_matrix(X)\n",
    "Xc = (X.T * X)\n",
    "# 対角成分のみにする\n",
    "Xc = np.triu(Xc.toarray())\n",
    "\n",
    "# DataFrame 型に整える\n",
    "cooccur_75_df = pd.DataFrame(Xc, columns=cross_75_df.columns, index=cross_75_df.columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cooccur_75_df.shape)\n",
    "display(cooccur_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed95a2-60f0-4248-948d-1a77f63136ee",
   "metadata": {},
   "source": [
    "#### 1.7.2 Jaccard 係数を求める (抽出語-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d053b-5d08-4aea-9052-f4909bec75b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 共起行列の中身を Jaccard 係数に入れ替える\n",
    "jaccard_75_df = gssm_utils.jaccard_coef(cooccur_75_df, cross_75_df)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(jaccard_75_df.shape)\n",
    "display(jaccard_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb73da-5154-41a5-ad24-3f76038be128",
   "metadata": {},
   "source": [
    "#### 1.7.3 プロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236a1f2-2cb2-4dba-8da3-dee524f24b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 抽出語の出現回数(ノードの大きさ)を取得する\n",
    "word_counts = cross_75_df.sum(axis=0).values\n",
    "\n",
    "# 共起行列(Jaccard係数)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_cooccur_network(jaccard_75_df, word_counts, np.sort(jaccard_75_df.values.reshape(-1))[::-1][60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133def7e-50ce-4166-b8a5-8717df4f5609",
   "metadata": {},
   "source": [
    "### 1.8 係り受けネットワーク図 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae862d88-43fb-49f9-a767-1b03249ac680",
   "metadata": {},
   "source": [
    "#### 1.8.1 係り受け行列を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bcb28-c74d-4059-9f8b-fa8aa851d528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# チャンク(文節)から単語を取り出す\n",
    "def get_words(tree, from_chunk, stopwords):\n",
    "\n",
    "    # チャンク(文節)の開始位置を取得する\n",
    "    beg = from_chunk.token_pos\n",
    "\n",
    "    # チャンクの開始位置を取得する\n",
    "    end = from_chunk.token_pos + from_chunk.token_size\n",
    "\n",
    "    # 抽出語情報リストの初期化\n",
    "    words = []\n",
    "\n",
    "    # チャンク(文節)ごとのループ\n",
    "    for i in range(beg, end):\n",
    "\n",
    "        # チャンク中の形態素を取り出す\n",
    "        token = tree.token(i)\n",
    "\n",
    "        # 解析結果を要素ごとにバラす\n",
    "        features = token.feature.split(',')\n",
    "\n",
    "        # 品詞1 を取り出す\n",
    "        pos1 = features[0]\n",
    "\n",
    "        # 品詞2 を取り出す\n",
    "        pos2 = features[1] if len(features) > 1 else \"\"\n",
    "\n",
    "        # 原形 を取り出す\n",
    "        base = features[6] if len(features) > 6 else None\n",
    "\n",
    "        # 原型がストップワードに含まれない単語のみ抽出する\n",
    "        if base not in stopwords:\n",
    "\n",
    "            # 「名詞-一般」\n",
    "            if (pos1 == \"名詞\" and pos2 == \"一般\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"名詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「形容動詞」\n",
    "            elif (pos1 == \"名詞\" and pos2 == \"形容動詞語幹\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                base = f\"{base}だ\"\n",
    "                postag = \"形容動詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「形容詞」\n",
    "            elif pos1 == \"形容詞\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"形容詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「未知語」\n",
    "            elif pos1 == \"未知語\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"未知語\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "    # 抽出語情報をリストを返却する\n",
    "    return words\n",
    "\n",
    "\n",
    "# 必要ライブラリのインポート\n",
    "import CaboCha\n",
    "\n",
    "# cabocha の初期化\n",
    "cp = CaboCha.Parser(\"-r ../tools/usr/local/etc/cabocharc\")\n",
    "\n",
    "# 半角->全角変換マクロを定義する\n",
    "ZEN = \"\".join(chr(0xff01 + i) for i in range(94))\n",
    "HAN = \"\".join(chr(0x21 + i) for i in range(94))\n",
    "HAN2ZEN = str.maketrans(HAN, ZEN)\n",
    "\n",
    "# ストップワードを定義する\n",
    "# stopwords = ['する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう']\n",
    "stopwords = ['*']  # 原形に 「'*'」 が出力された場合に除去するため\n",
    "\n",
    "# 係り受けペア辞書の初期化\n",
    "pair_counts = defaultdict(lambda: 0)\n",
    "pairs = []\n",
    "\n",
    "# データ1行ごとのループ\n",
    "for index, row in all_df.iterrows():\n",
    "\n",
    "    # 半角->全角変換した後で, cabocha で解析する\n",
    "    tree = cp.parse(row[\"コメント\"].translate(HAN2ZEN))\n",
    "\n",
    "    # 解析結果から空でないチャンク(文節)のリストを集める\n",
    "    chunks = {}\n",
    "    key = 0\n",
    "    for i in range(tree.size()):\n",
    "        tok = tree.token(i)\n",
    "        if tok.chunk:\n",
    "            chunks[key] = tok.chunk\n",
    "            key += 1\n",
    "\n",
    "    # 係り元と係り先の単語情報(原形と品詞)を集める\n",
    "    for from_chunk in chunks.values():\n",
    "        # 係り先がなければスキップ\n",
    "        if from_chunk.link < 0:\n",
    "            continue\n",
    "\n",
    "        # 係り先のチャンク(文節)を取得する\n",
    "        to_chunk = chunks[from_chunk.link]\n",
    "\n",
    "        # 係り元の単語情報(原形と品詞)を取得する\n",
    "        from_words = get_words(tree, from_chunk, stopwords)\n",
    "\n",
    "        # 係り先の単語情報(原形と品詞)を取得する\n",
    "        to_words = get_words(tree, to_chunk, stopwords)\n",
    "\n",
    "    # 係り受けペアと頻度を収集する\n",
    "    for f in from_words:\n",
    "        for t in to_words:\n",
    "            key = (f[0], t[0])\n",
    "            pair_counts[key] += 1\n",
    "\n",
    "\n",
    "# 係り受け行列を初期化する (共起行列と同じ形)\n",
    "Xd = np.zeros(cooccur_75_df.shape)\n",
    "\n",
    "# 係り受けペアを係り受け列に変換する\n",
    "for (f,t), v in pair_counts.items():\n",
    "    columns = list(cooccur_75_df.columns)\n",
    "    if f in columns and t in columns:\n",
    "        i = columns.index(f)\n",
    "        j = columns.index(t)\n",
    "        Xd[i,j] = v\n",
    "\n",
    "# DataFrme 型に整える\n",
    "dep_75_df = pd.DataFrame(Xd, columns=cooccur_75_df.columns, index=cooccur_75_df.columns)\n",
    "print(dep_75_df.shape)\n",
    "display(dep_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c0686-8812-4299-b0d6-09c8c5a91547",
   "metadata": {},
   "source": [
    "#### 1.8.2 条件付き確率を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2750d3-7da7-4698-81d4-cf46ece7be90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 係り受け行列の中身(numpy行列)を取り出す\n",
    "Xc = dep_75_df.values\n",
    "\n",
    "# 係り受け行列(条件付き確率)を初期化する (元の係り受け行列と同じ形)\n",
    "Xd = np.zeros(Xc.shape)\n",
    "\n",
    "# 係り元単語の出現頻度を取得する\n",
    "word_counts = cooccur_75_df.sum(axis=0).values\n",
    "\n",
    "# 係り受けペアごとのループ\n",
    "for (f,t), v in pair_counts.items():\n",
    "    columns = list(dep_75_df.columns)\n",
    "\n",
    "    # 係り元と係り先の両方が列に含まれる\n",
    "    if f in columns and t in columns:\n",
    "        i = columns.index(f)\n",
    "        j = columns.index(t)\n",
    "\n",
    "        # 条件付き確率(係り受け頻度/係り先出現回数)を求める\n",
    "        Xd[i,j] = v / word_counts[i]\n",
    "\n",
    "# DataFrame 型に整える\n",
    "dep_75_df = pd.DataFrame(Xd, columns=dep_75_df.columns, index=dep_75_df.columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(dep_75_df.shape)\n",
    "display(dep_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadfbfc-a59d-4521-9a83-df8d151ad94d",
   "metadata": {},
   "source": [
    "#### 1.8.3 プロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e01ec-a6fe-4aa0-9a45-76f3048711d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 抽出語の出現回数(ノードの大きさ)を取得する\n",
    "word_counts = cross_75_df.sum(axis=0).values\n",
    "\n",
    "# 係り受け(条件付き確率)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_dependency_network(dep_75_df, word_counts, np.sort(dep_75_df.values.reshape(-1))[::-1][60], pyvis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e4380-5010-4c7b-bfa6-a7d31d33cc9c",
   "metadata": {},
   "source": [
    "### 1.9 対応分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e9a848-977a-4384-913a-4caa32cd6555",
   "metadata": {},
   "source": [
    "「文書-抽出語」 表を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3655d-0de3-4261-a75b-683924eb3958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75d709-9858-44fe-8c3e-848096449075",
   "metadata": {},
   "source": [
    "#### 1.9.1 「外部変数-抽出語」 クロス集計表を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701946c-4d70-447e-8ef3-9fc2bff33e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_75_df = pd.concat(\n",
    "    [\n",
    "        cross_75_df.groupby(level='カテゴリー').sum(), \n",
    "        cross_75_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_75_df.shape)\n",
    "display(aggregate_75_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe18698-0c76-4da1-8279-c720716a401b",
   "metadata": {},
   "source": [
    "#### 1.9.2 対応分析プロットを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b390d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "import mca\n",
    "\n",
    "# ライブラリ mca による対応分析\n",
    "ncols = aggregate_75_df.shape[1]\n",
    "mca_ben = mca.MCA(aggregate_75_df, ncols=ncols, benzecri=False)\n",
    "\n",
    "# 行方向および列方向の値を取り出す\n",
    "row_coord = mca_ben.fs_r(N=2)\n",
    "col_coord = mca_ben.fs_c(N=2)\n",
    "\n",
    "# 固有値を求める\n",
    "eigenvalues = mca_ben.L\n",
    "total = np.sum(eigenvalues)\n",
    "# 寄与率を求める\n",
    "explained_inertia = 100 * eigenvalues / total\n",
    "\n",
    "# 行方向および列方向のラベルを取得する\n",
    "row_labels = aggregate_75_df.index\n",
    "col_labels = aggregate_75_df.columns\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_coresp(row_coord, col_coord, row_labels, col_labels, explained_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c196efc-b548-4be5-ae0e-2784d26fa6c5",
   "metadata": {},
   "source": [
    "### 1.10 トピックモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c0604-d440-4ee9-bfd7-503e03491e4d",
   "metadata": {},
   "source": [
    "「文書-抽出語」 表を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc745ac6-145f-4890-8eb0-d1ed04e7b145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame を表示する\n",
    "print(cross_75_df.shape)\n",
    "display(cross_75_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9839a-a004-47a9-958e-c26c92b9cefc",
   "metadata": {},
   "source": [
    "#### 1.10.1 トピックを抽出する (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff4904-3dbe-4637-900e-bc0365a159e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# ライブラリ LDA によるトピック抽出\n",
    "lda = LDA(max_iter=25, learning_method='batch', random_state=42, n_jobs=-1, n_components=6)\n",
    "lda.fit(cross_75_df.values)\n",
    "\n",
    "# トピックごとに出現確率Top 20語を表示する\n",
    "n_top_words = 20\n",
    "feature_names = cross_75_df.columns\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic # {topic_idx+1}:\", end=\" \")\n",
    "    for i in topic.argsort()[:-n_top_words-1:-1]:\n",
    "        print(feature_names[i], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13899d5f",
   "metadata": {},
   "source": [
    "ChatGPT を使ってトピックを説明する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34223c2c",
   "metadata": {},
   "source": [
    "プロンプトの例:\n",
    "> 以下はトピックとトピックごとの高確率ワードです. これを読んで各トピックの要約を日本語で作成してください.\n",
    "> \n",
    "> Topic # 1\tフロント ホテル 浴場 部屋 親切だ 良い …"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704c6b7",
   "metadata": {},
   "source": [
    "結果の例:\n",
    "- トピック1: ホテルのスタッフと設備\n",
    "- トピック2: ホテルの立地と利便性\n",
    "- トピック3: 温泉と食事の質\n",
    "- トピック4: スタッフの対応と設備の質\n",
    "- トピック5: 部屋の質と価格\n",
    "- トピック6: 部屋の広さと快適さ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0b8e1-6d13-403c-8fc0-2b474ee1a830",
   "metadata": {},
   "source": [
    "#### 1.10.2 トピックをワードクラウドで描画する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964af57-f372-44fb-9b37-6e5cdd555115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# トピックごとに出現確率Top 75語でワードクラウドを作成する\n",
    "n_top_words = 75\n",
    "gssm_utils.plot_topic_model(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcebef",
   "metadata": {},
   "source": [
    "#### 1.10.3 トピック分布をプロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61906c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書ごとのトピック比率を取得\n",
    "doc_topic_distributions = lda.transform(cross_75_df.values)\n",
    "\n",
    "# 文書全体のトピック比率を計算（平均を取る）\n",
    "overall_topic_distribution = np.mean(doc_topic_distributions, axis=0)\n",
    "\n",
    "gssm_utils.plot_topic_distribution(overall_topic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb028d1e-756d-4cff-bd8a-6a87ce6e2214",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40790a01-51e1-48df-8ecb-a9ed4c89d070",
   "metadata": {},
   "source": [
    "### 1.11 外部変数の利用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdfee48",
   "metadata": {},
   "source": [
    "#### 1.11.1 「文書-抽出語」表の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ae3da",
   "metadata": {},
   "source": [
    "「文書-抽出語」表を作成する (出現回数 Top 150語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 150語のみ抽出する\n",
    "word_counts_150_df = word_counts_df[0:150]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 150語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_150_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_150_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# 「カテゴリー,エリア」でクロス集計する\n",
    "cross_150_df = pd.crosstab(\n",
    "    [\n",
    "        docs_150_df['カテゴリー'], \n",
    "        docs_150_df['エリア'], \n",
    "        docs_150_df['文書ID']\n",
    "    ], \n",
    "    docs_150_df['単語ID'], margins=False\n",
    ")\n",
    "cross_150_df.columns = word_counts_150_df[\"表層\"]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_150_df.shape)\n",
    "display(cross_150_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3242b27",
   "metadata": {},
   "source": [
    "「文書-抽出語」表を {0,1} に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表を {0,1} に変換する\n",
    "cross_150_df[cross_150_df > 0] = 1\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_150_df.shape)\n",
    "display(cross_150_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4226699",
   "metadata": {},
   "source": [
    "#### 1.11.2 共起行列を作成する (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139edac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_df = pd.concat(\n",
    "    [\n",
    "        cross_150_df.groupby(level='カテゴリー').sum(),\n",
    "        cross_150_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_df.shape)\n",
    "display(aggregate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44de28a",
   "metadata": {},
   "source": [
    "#### 1.11.3 Jaccard 係数を求める (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出語の出現回数を取得する\n",
    "word_counts = cross_150_df.sum(axis=0).values\n",
    "\n",
    "# 属性(外部変数)出現数を取得する\n",
    "attr_counts = np.hstack(\n",
    "    [\n",
    "        all_df.value_counts('カテゴリー').values,\n",
    "        all_df.value_counts('エリア').values\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 共起行列の中身を Jaccard 係数に入れ替える\n",
    "jaccard_attrs_df = gssm_utils.jaccard_attrs_coef(aggregate_df, attr_counts, word_counts, total=10000, conditional=False)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(jaccard_attrs_df.shape)\n",
    "display(jaccard_attrs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc483ed",
   "metadata": {},
   "source": [
    "#### 1.11.4 特徴語ランキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「カテゴリ」や「エリア」ごとに Jaccard 係数のTop 10語を抽出する\n",
    "df_list = []\n",
    "for index, row in jaccard_attrs_df.iterrows():\n",
    "    df_list.append(row.iloc[np.argsort(row.values)[::-1][:10]].reset_index())\n",
    "\n",
    "# 「カテゴリ」や「エリア」ごとの Jaccard 係数のTop 10 を横方向に連結した DetaFrame を作成する\n",
    "ranking_df = pd.DataFrame(pd.concat(df_list, axis=1))\n",
    "ranking_df.columns = np.array([c for pair in [[x,f\"jaccard\"] for x in jaccard_attrs_df.index] for c in pair], dtype='object')\n",
    "\n",
    "# DataFrame を表示する\n",
    "display(ranking_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957e9f2",
   "metadata": {},
   "source": [
    "#### 1.11.5 ワードクラウド (カテゴリーごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cde080",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in cross_150_df.groupby(level='カテゴリー'):\n",
    "    print(name)\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # プロットする\n",
    "    gssm_utils.plot_wordcloud(\" \".join(group_cross_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a0dfb",
   "metadata": {},
   "source": [
    "#### 1.11.6 共起ネットワーク図 (カテゴリーごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "for name, group in cross_150_df.groupby(level='カテゴリー'):\n",
    "    print(name)\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 共起行列の中身を Jaccard 係数に入れ替える\n",
    "    group_jaccard_df = gssm_utils.jaccard_coef(group_cooccur_df, group_cross_df)\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group.sum(axis=0).values\n",
    "\n",
    "    # プロットする\n",
    "    gssm_utils.plot_cooccur_network(group_jaccard_df, word_counts, np.sort(group_jaccard_df.values.reshape(-1))[::-1][60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee92fa",
   "metadata": {},
   "source": [
    "#### 1.11.7 トピック分布 (カテゴリーごと)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3730f7",
   "metadata": {},
   "source": [
    "#### 1.11.7.1 文書全体からトピックを抽出する (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# ライブラリ LDA によるトピック抽出\n",
    "lda = LDA(max_iter=25, learning_method='batch', random_state=42, n_jobs=-1, n_components=6)\n",
    "lda.fit(cross_150_df.values)\n",
    "\n",
    "# トピックごとに出現確率Top 20語を表示する\n",
    "n_top_words = 20\n",
    "feature_names = cross_150_df.columns\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic # {topic_idx+1}:\", end=\" \")\n",
    "    for i in topic.argsort()[:-n_top_words-1:-1]:\n",
    "        print(feature_names[i], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f9108",
   "metadata": {},
   "source": [
    "#### 1.11.7.2 トピックをワードクラウドで描画する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トピックごとに出現確率Top 75語でワードクラウドを作成する\n",
    "n_top_words = 75\n",
    "gssm_utils.plot_topic_model(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df0617",
   "metadata": {},
   "source": [
    "#### 1.11.7.3 トピック分布をプロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7808b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in cross_150_df.groupby(level='カテゴリー'):\n",
    "    print(name)\n",
    "\n",
    "    # 文書ごとのトピック比率を取得\n",
    "    doc_topic_distributions = lda.transform(group.values)\n",
    "\n",
    "    # 文書全体のトピック比率を計算（平均を取る）\n",
    "    overall_topic_distribution = np.mean(doc_topic_distributions, axis=0)\n",
    "\n",
    "    gssm_utils.plot_topic_distribution(overall_topic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecdb0d",
   "metadata": {},
   "source": [
    "#### 1.11.8 本文の参照 (カテゴリーごと)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edeec08",
   "metadata": {},
   "source": [
    "「夕食」「残念」という単語が含まれている口コミを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b34bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in docs_df.groupby('カテゴリー'):\n",
    "    print(name)\n",
    "\n",
    "    search_index = all_df['コメント'].str.contains('夕食') & all_df['コメント'].str.contains('残念')\n",
    "\n",
    "    display(all_df[search_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb67ed9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02822ddc",
   "metadata": {},
   "source": [
    "## 【演習】 外部変数を利用したエリアごとの作図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034dc112",
   "metadata": {},
   "source": [
    "注意: 以下の演習は上のセルを全て実行してから続けて実施してください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca0d74",
   "metadata": {},
   "source": [
    "#### 2.1 【演習】 ワードクラウド (エリアごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: 1.11.5 のセル中のコードをコピーして貼り付け,「カテゴリー」を「エリア」に変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124977d8",
   "metadata": {},
   "source": [
    "#### 2.2 【演習】 共起ネットワーク図 (エリアごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: 1.11.6 のセル中のコードをコピーして貼り付け,「カテゴリー」を「エリア」に変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f87cb",
   "metadata": {},
   "source": [
    "#### 2.3 【演習】 トピック分布 (エリアごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: 1.11.7.2 のセル中のコードをコピーして貼り付け,そのまま実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: 1.11.7.3 のセル中のコードをコピーして貼り付け,「カテゴリー」を「エリア」に変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73506e2e",
   "metadata": {},
   "source": [
    "#### 2.4 【演習】 本文の参照 (エリアごと)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edadac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ToDo: 1.11.8 のセル中のコードをコピーして貼り付け,「カテゴリー」を「エリア」に変更する"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gssm2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
